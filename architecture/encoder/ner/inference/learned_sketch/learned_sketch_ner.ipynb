{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T21:18:45.685154Z",
          "iopub.status.busy": "2025-10-07T21:18:45.684606Z",
          "iopub.status.idle": "2025-10-07T21:18:49.473928Z",
          "shell.execute_reply": "2025-10-07T21:18:49.473311Z",
          "shell.execute_reply.started": "2025-10-07T21:18:45.685129Z"
        },
        "id": "NBGzobTPxf_u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.n_heads = config.n_heads\n",
        "        self.dim = config.dim\n",
        "        self.dropout = nn.Dropout(p=getattr(config, \"attention_dropout\", 0.0))\n",
        "\n",
        "        if self.dim % self.n_heads != 0:\n",
        "            raise ValueError(f\"n_heads ({self.n_heads}) must divide dim ({self.dim})\")\n",
        "\n",
        "        self.attention_head_size = self.dim // self.n_heads\n",
        "\n",
        "        self.q_lin = nn.Linear(self.dim, self.dim)\n",
        "        self.k_lin = nn.Linear(self.dim, self.dim)\n",
        "        self.v_lin = nn.Linear(self.dim, self.dim)\n",
        "        self.out_lin = nn.Linear(self.dim, self.dim)\n",
        "\n",
        "       #the nn.adap later inatead of the learned e and f\n",
        "        self.linformer_k = 256\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool1d(self.linformer_k)\n",
        "\n",
        "\n",
        "    def _prepare_heads(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        bs, seq_len, _ = x.size()\n",
        "        return x.view(bs, seq_len, self.n_heads, self.attention_head_size).transpose(1, 2)\n",
        "\n",
        "    def _compress_sequence(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Transpose to (bs, dim, seq_len) for pooling, then back\n",
        "        x_pooled = self.adaptive_pool(x.transpose(1, 2))\n",
        "        return x_pooled.transpose(1, 2)\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        query: torch.Tensor,\n",
        "        key: torch.Tensor,\n",
        "        value: torch.Tensor,\n",
        "        mask: Optional[torch.Tensor] = None,\n",
        "        head_mask: Optional[torch.Tensor] = None,\n",
        "        output_attentions: bool = False,\n",
        "    ) -> Tuple[torch.Tensor, ...]:\n",
        "        bs, q_len, _ = query.size()\n",
        "\n",
        "        Q = self.q_lin(query)\n",
        "        K = self.k_lin(key)\n",
        "        V = self.v_lin(value)\n",
        "\n",
        "        if mask is not None:\n",
        "            if mask.dim() == 4:\n",
        "                bool_mask = mask.squeeze(1).squeeze(1) < 0\n",
        "            elif mask.dim() == 3:\n",
        "                bool_mask = mask.squeeze(1) < 0\n",
        "            else:\n",
        "                bool_mask = mask < 0\n",
        "\n",
        "            bool_mask = bool_mask.unsqueeze(-1)\n",
        "            K = K.masked_fill(bool_mask, 0.0)\n",
        "            V = V.masked_fill(bool_mask, 0.0)\n",
        "\n",
        "        K_compressed = self._compress_sequence(K)\n",
        "        V_compressed = self._compress_sequence(V)\n",
        "\n",
        "\n",
        "\n",
        "        Q = self._prepare_heads(Q)\n",
        "        K_compressed = self._prepare_heads(K_compressed)\n",
        "        V_compressed = self._prepare_heads(V_compressed)\n",
        "\n",
        "        head_dim = self.attention_head_size\n",
        "        Q = Q / math.sqrt(head_dim)\n",
        "\n",
        "        scores = torch.matmul(Q, K_compressed.transpose(-2, -1))\n",
        "\n",
        "\n",
        "        weights = nn.functional.softmax(scores, dim=-1)\n",
        "        weights = self.dropout(weights)\n",
        "\n",
        "        if head_mask is not None:\n",
        "            if head_mask.dim() == 1:\n",
        "                head_mask = head_mask.view(1, -1, 1, 1)\n",
        "            elif head_mask.dim() == 2:\n",
        "                head_mask = head_mask.unsqueeze(0).unsqueeze(2)\n",
        "            weights = weights * head_mask\n",
        "\n",
        "        context = torch.matmul(weights, V_compressed)\n",
        "        context = context.transpose(1, 2).contiguous().view(bs, q_len, self.dim)\n",
        "        context = self.out_lin(context)\n",
        "\n",
        "        if output_attentions:\n",
        "            return (context, weights)\n",
        "\n",
        "        return (context,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T21:19:01.916507Z",
          "iopub.status.busy": "2025-10-07T21:19:01.916106Z",
          "iopub.status.idle": "2025-10-07T21:19:17.422260Z",
          "shell.execute_reply": "2025-10-07T21:19:17.421292Z",
          "shell.execute_reply.started": "2025-10-07T21:19:01.916485Z"
        },
        "id": "MD3MIxuj3u8-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -U transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T21:19:33.981431Z",
          "iopub.status.busy": "2025-10-07T21:19:33.980636Z",
          "iopub.status.idle": "2025-10-07T21:20:08.249870Z",
          "shell.execute_reply": "2025-10-07T21:20:08.248911Z",
          "shell.execute_reply.started": "2025-10-07T21:19:33.981393Z"
        },
        "id": "SPaYx2mJxf_w",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/distilbert-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/distilbert-NER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3iiRXC0xf_y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#mha with kev attention, remove this cell for vanilla\n",
        "for i, layer in enumerate(model.distilbert.transformer.layer):\n",
        "    custom_attention = MultiHeadSelfAttention(model.config, top_k=32)\n",
        "    custom_attention.q_lin.load_state_dict(layer.attention.q_lin.state_dict())\n",
        "    custom_attention.k_lin.load_state_dict(layer.attention.k_lin.state_dict())\n",
        "    custom_attention.v_lin.load_state_dict(layer.attention.v_lin.state_dict())\n",
        "    custom_attention.out_lin.load_state_dict(layer.attention.out_lin.state_dict())\n",
        "    custom_attention.to(device)\n",
        "    layer.attention = custom_attention\n",
        "\n",
        "print(\"loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T21:49:29.871859Z",
          "iopub.status.busy": "2025-10-07T21:49:29.871251Z",
          "iopub.status.idle": "2025-10-07T21:49:38.982903Z",
          "shell.execute_reply": "2025-10-07T21:49:38.982353Z",
          "shell.execute_reply.started": "2025-10-07T21:49:29.871836Z"
        },
        "id": "ra2LjVg93u9B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"eriktks/conll2003\",revision=\"convert/parquet\")\n",
        "\n",
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T21:59:09.089880Z",
          "iopub.status.busy": "2025-10-07T21:59:09.089586Z",
          "iopub.status.idle": "2025-10-07T21:59:09.094902Z",
          "shell.execute_reply": "2025-10-07T21:59:09.094294Z",
          "shell.execute_reply.started": "2025-10-07T21:59:09.089860Z"
        },
        "id": "NzFqOqDZ3u9B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ds['train'].features[\"ner_tags\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:00:15.305074Z",
          "iopub.status.busy": "2025-10-07T22:00:15.304424Z",
          "iopub.status.idle": "2025-10-07T22:00:17.186984Z",
          "shell.execute_reply": "2025-10-07T22:00:17.186418Z",
          "shell.execute_reply.started": "2025-10-07T22:00:15.305048Z"
        },
        "id": "RoShR8wq3u9C",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Get the label mappings from the dataset\n",
        "label_list = [\n",
        "    \"O\",       # Outside of a named entity\n",
        "    \"B-PER\",   # Beginning of a person entity\n",
        "    \"I-PER\",   # Inside a person entity\n",
        "    \"B-ORG\",   # Beginning of an organization entity\n",
        "    \"I-ORG\",   # Inside an organization entity\n",
        "    \"B-LOC\",   # Beginning of a location entity\n",
        "    \"I-LOC\",   # Inside a location entity\n",
        "    \"B-MISC\",  # Beginning of a miscellaneous entity\n",
        "    \"I-MISC\"   # Inside a miscellaneous entity\n",
        "]\n",
        "\n",
        "# Create the label mappings\n",
        "id2label = {i: label for i, label in enumerate(label_list)}\n",
        "label2id = {label: i for i, label in id2label.items()}\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None: # Special tokens like [CLS], [SEP]\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx: # First token of a new word\n",
        "                label_ids.append(label[word_idx])\n",
        "            else: # Subsequent subword tokens\n",
        "                label_ids.append(-100) # We only label the first token of a word\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "print(\"Tokenizing and aligning labels for the dataset...\")\n",
        "tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "# âœ¨ CORRECTIVE LINE ADDED HERE âœ¨\n",
        "# Remove columns that the model doesn't need and that cause the error\n",
        "tokenized_ds = tokenized_ds.remove_columns(['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'])\n",
        "\n",
        "\n",
        "# Use the test split for evaluation\n",
        "eval_dataset = tokenized_ds[\"test\"]\n",
        "\n",
        "# Data collator handles dynamic padding for token classification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "# Create DataLoader\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    batch_size=32, # You can adjust the batch size\n",
        "    collate_fn=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T21:53:37.592825Z",
          "iopub.status.busy": "2025-10-07T21:53:37.592272Z",
          "iopub.status.idle": "2025-10-07T21:53:43.543233Z",
          "shell.execute_reply": "2025-10-07T21:53:43.542243Z",
          "shell.execute_reply.started": "2025-10-07T21:53:37.592798Z"
        },
        "id": "M0gw9AzK3u9D",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install seqeval --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T21:56:44.879484Z",
          "iopub.status.busy": "2025-10-07T21:56:44.879234Z",
          "iopub.status.idle": "2025-10-07T21:56:51.427713Z",
          "shell.execute_reply": "2025-10-07T21:56:51.426887Z",
          "shell.execute_reply.started": "2025-10-07T21:56:44.879467Z"
        },
        "id": "R_omBO0cxf_3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install codecarbon --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:00:26.956092Z",
          "iopub.status.busy": "2025-10-07T22:00:26.955391Z",
          "iopub.status.idle": "2025-10-07T22:00:40.817717Z",
          "shell.execute_reply": "2025-10-07T22:00:40.816875Z",
          "shell.execute_reply.started": "2025-10-07T22:00:26.956068Z"
        },
        "id": "1yTFUfm33u9E",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from codecarbon import EmissionsTracker\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
        "from seqeval.scheme import IOB2 # For metrics calculation\n",
        "\n",
        "# --- Constants ---\n",
        "RESULTS_DIR = \"./ner_test_results\"\n",
        "CARBON_DIR = \"./ner_carbon_emissions\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(CARBON_DIR, exist_ok=True)\n",
        "RESULTS_FILE = os.path.join(RESULTS_DIR, \"ner_inference_metrics.csv\")\n",
        "\n",
        "def run_inference_ner(model: AutoModelForTokenClassification, data_loader: DataLoader, device: str):\n",
        "    \"\"\"\n",
        "    Runs the NER inference loop.\n",
        "    Returns lists of true and predicted label sequences for seqeval.\n",
        "    \"\"\"\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_true_labels = []\n",
        "    all_predictions = []\n",
        "    batch_times = []\n",
        "    memory_usage = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(data_loader, desc=\"NER Inference\"):\n",
        "            # Move batch to device\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "\n",
        "            batch_start = time.time()\n",
        "            outputs = model(**batch)\n",
        "            batch_times.append(time.time() - batch_start)\n",
        "\n",
        "            # **KEY CHANGE FOR NER**: Argmax on dimension 2\n",
        "            predictions = torch.argmax(outputs.logits, dim=2)\n",
        "            true_labels = batch[\"labels\"]\n",
        "\n",
        "            # **KEY CHANGE FOR METRICS**: Remove padding and align for seqeval\n",
        "            # We need to convert predictions and labels back to lists of strings\n",
        "            for i in range(true_labels.size(0)):\n",
        "                true_label_sequence = []\n",
        "                pred_label_sequence = []\n",
        "                for label, pred in zip(true_labels[i], predictions[i]):\n",
        "                    if label != -100: # Ignore padding and subword labels\n",
        "                        true_label_sequence.append(id2label[label.item()])\n",
        "                        pred_label_sequence.append(id2label[pred.item()])\n",
        "                all_true_labels.append(true_label_sequence)\n",
        "                all_predictions.append(pred_label_sequence)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                memory_used = torch.cuda.max_memory_allocated() / (1024**3)\n",
        "                memory_usage.append(memory_used)\n",
        "                torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    return all_true_labels, all_predictions, batch_times, memory_usage\n",
        "\n",
        "def calculate_and_log_metrics_ner(true_labels, predictions, batch_times, memory_usage, emissions_kg, output_path):\n",
        "    \"\"\"\n",
        "    Calculates and logs NER performance metrics using seqeval.\n",
        "    \"\"\"\n",
        "    total_inference_time = sum(batch_times)\n",
        "\n",
        "    # **KEY CHANGE**: Use seqeval for metrics\n",
        "    report = classification_report(true_labels, predictions, output_dict=True, mode='strict', scheme=IOB2)\n",
        "\n",
        "    # Extract overall metrics from the report\n",
        "    overall_precision = report['micro avg']['precision']\n",
        "    overall_recall = report['micro avg']['recall']\n",
        "    overall_f1 = report['micro avg']['f1-score']\n",
        "\n",
        "    metrics = {\n",
        "        'total_inference_time': total_inference_time,\n",
        "        'avg_batch_time': total_inference_time / len(batch_times) if batch_times else 0,\n",
        "        'emissions_kg': emissions_kg,\n",
        "        'overall_precision': overall_precision,\n",
        "        'overall_recall': overall_recall,\n",
        "        'overall_f1': overall_f1,\n",
        "        'avg_memory_used_gb': np.mean(memory_usage) if memory_usage else 0\n",
        "    }\n",
        "\n",
        "    pd.DataFrame([metrics]).to_csv(output_path, index=False)\n",
        "\n",
        "    # Print the detailed, per-entity report\n",
        "    print(\"\\n--- NER Classification Report ---\")\n",
        "    print(classification_report(true_labels, predictions, mode='strict', scheme=IOB2))\n",
        "    print(\"---------------------------------\")\n",
        "\n",
        "    print(f\"ðŸŽ¯ NER Inference Complete!\")\n",
        "    print(f\"â° Total Time: {metrics['total_inference_time']:.2f}s\")\n",
        "    print(f\"ðŸŒ± Emissions: {metrics['emissions_kg']:.6f} kg CO2\")\n",
        "    print(f\"ðŸ“ˆ Overall F1 Score: {metrics['overall_f1']:.4f}\")\n",
        "    print(f\"ðŸ“Š Overall Precision: {metrics['overall_precision']:.4f}\")\n",
        "    print(f\"ðŸ“Š Overall Recall: {metrics['overall_recall']:.4f}\")\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Track carbon emissions\n",
        "tracker = EmissionsTracker(output_dir=CARBON_DIR, project_name=\"ner_inference\", log_level='critical')\n",
        "tracker.start()\n",
        "\n",
        "# Run inference\n",
        "true_labels, predictions, batch_times, memory_usage = run_inference_ner(model, eval_dataloader, device)\n",
        "\n",
        "# Stop tracker and get emissions\n",
        "emissions_kg = tracker.stop()\n",
        "\n",
        "# Calculate and log metrics\n",
        "calculate_and_log_metrics_ner(true_labels, predictions, batch_times, memory_usage, emissions_kg, RESULTS_FILE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:39.436848Z",
          "iopub.status.busy": "2025-10-07T22:07:39.435956Z",
          "iopub.status.idle": "2025-10-07T22:07:39.456670Z",
          "shell.execute_reply": "2025-10-07T22:07:39.455952Z",
          "shell.execute_reply.started": "2025-10-07T22:07:39.436815Z"
        },
        "id": "jeTjLxd63u9F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Select a sample from the original test dataset\n",
        "example_index = 15\n",
        "tokens = ds['test'][example_index]['tokens']\n",
        "\n",
        "print(\"Original Tokens:\")\n",
        "print(tokens)\n",
        "\n",
        "# Tokenize the words, adding special tokens and converting to PyTorch tensors\n",
        "inputs = tokenizer(\n",
        "    tokens,\n",
        "    is_split_into_words=True,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# Move inputs to the same device as the model\n",
        "inputs = inputs.to(device)\n",
        "\n",
        "# Get model output with attentions\n",
        "output = model(**inputs, output_attentions=True)\n",
        "\n",
        "# The 'attentions' object is a tuple of tensors, one for each layer\n",
        "attentions = output.attentions\n",
        "\n",
        "print(f\"Number of layers: {len(attentions)}\")\n",
        "# Shape: (batch_size, num_heads, sequence_length, sequence_length)\n",
        "print(f\"Shape of one attention tensor (first layer): {attentions[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:39.664898Z",
          "iopub.status.busy": "2025-10-07T22:07:39.664628Z",
          "iopub.status.idle": "2025-10-07T22:07:51.491785Z",
          "shell.execute_reply": "2025-10-07T22:07:51.490798Z",
          "shell.execute_reply.started": "2025-10-07T22:07:39.664880Z"
        },
        "id": "reVAWUWwxf_6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#hist layer vise\n",
        "num_layers = len(attentions)\n",
        "num_heads = attentions[0].size(1)\n",
        "\n",
        "fig, axes = plt.subplots(num_layers, num_heads, figsize=(20, 15))\n",
        "\n",
        "for layer_idx, layer_attn in enumerate(attentions):\n",
        "    # Take first example from batch (instead of averaging)\n",
        "    attn = layer_attn[0]  # shape: [num_heads, seq_len, seq_len]\n",
        "\n",
        "    for head_idx in range(num_heads):\n",
        "        values = attn[head_idx].detach().cpu().numpy().flatten()\n",
        "\n",
        "        ax = axes[layer_idx, head_idx] if num_layers > 1 else axes[head_idx]\n",
        "        ax.hist(values, bins=50)  # zoom in on [0, 0.3]\n",
        "        ax.set_title(f\"Layer:{layer_idx} Head:{head_idx}\")\n",
        "        ax.set_xlabel(\"Attention weight\")\n",
        "        ax.set_ylabel(\"Count\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:51.493289Z",
          "iopub.status.busy": "2025-10-07T22:07:51.493052Z",
          "iopub.status.idle": "2025-10-07T22:07:55.018626Z",
          "shell.execute_reply": "2025-10-07T22:07:55.017663Z",
          "shell.execute_reply.started": "2025-10-07T22:07:51.493270Z"
        },
        "id": "Mu9Vprmoxf_7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install bertviz --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.020149Z",
          "iopub.status.busy": "2025-10-07T22:07:55.019841Z",
          "iopub.status.idle": "2025-10-07T22:07:55.028189Z",
          "shell.execute_reply": "2025-10-07T22:07:55.027365Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.020118Z"
        },
        "id": "4gHa3mIN3u9H",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.030458Z",
          "iopub.status.busy": "2025-10-07T22:07:55.030156Z",
          "iopub.status.idle": "2025-10-07T22:07:55.041536Z",
          "shell.execute_reply": "2025-10-07T22:07:55.040725Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.030437Z"
        },
        "id": "Hpx3o7k1xf_8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "input = inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.042752Z",
          "iopub.status.busy": "2025-10-07T22:07:55.042448Z",
          "iopub.status.idle": "2025-10-07T22:07:55.058575Z",
          "shell.execute_reply": "2025-10-07T22:07:55.057842Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.042731Z"
        },
        "id": "-tUci0plxf_8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Convert all sequences in batch\n",
        "all_tokens = [\n",
        "    tokenizer.convert_ids_to_tokens(seq.tolist())\n",
        "    for seq in input[\"input_ids\"]\n",
        "]\n",
        "\n",
        "for i, tokens in enumerate(all_tokens):\n",
        "    print(f\"Sequence {i} tokens:\", tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.059855Z",
          "iopub.status.busy": "2025-10-07T22:07:55.059554Z",
          "iopub.status.idle": "2025-10-07T22:07:55.094111Z",
          "shell.execute_reply": "2025-10-07T22:07:55.093338Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.059838Z"
        },
        "id": "cfZh8cM-xf_8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from bertviz import head_view\n",
        "\n",
        "# choose the first sequence in batch\n",
        "seq_index = 0\n",
        "\n",
        "# stack attentions across layers into [num_layers, num_heads, seq, seq]\n",
        "attention_stack = torch.stack([layer[seq_index] for layer in attentions])\n",
        "\n",
        "# add batch dimension â†’ [num_layers, 1, num_heads, seq, seq]\n",
        "attention_stack = attention_stack.unsqueeze(1)\n",
        "\n",
        "# tokens for that sequence\n",
        "tokens = all_tokens[seq_index]\n",
        "\n",
        "# visualize\n",
        "head_view(attention_stack, tokens, sentence_b_start=None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.095371Z",
          "iopub.status.busy": "2025-10-07T22:07:55.095092Z",
          "iopub.status.idle": "2025-10-07T22:07:55.351225Z",
          "shell.execute_reply": "2025-10-07T22:07:55.350240Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.095353Z"
        },
        "id": "B-FIBTcBxf_9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "layer, head = 1,1\n",
        "weights = attention_stack[layer, 0, head].detach().cpu()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(weights, xticklabels=tokens, yticklabels=tokens, cmap=\"viridis\")\n",
        "plt.title(f\"Layer {layer}, Head {head}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.352376Z",
          "iopub.status.busy": "2025-10-07T22:07:55.352141Z",
          "iopub.status.idle": "2025-10-07T22:07:55.375264Z",
          "shell.execute_reply": "2025-10-07T22:07:55.374559Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.352358Z"
        },
        "id": "YRXgFWunxf_9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from bertviz import model_view\n",
        "model_view(attention_stack,tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.376350Z",
          "iopub.status.busy": "2025-10-07T22:07:55.376154Z",
          "iopub.status.idle": "2025-10-07T22:07:55.396865Z",
          "shell.execute_reply": "2025-10-07T22:07:55.396096Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.376335Z"
        },
        "id": "Mqkwd8_Uxf_-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List\n",
        "\n",
        "# ---------- 1) tokens for all sequences ----------\n",
        "def tokens_for_all(inputs, tokenizer):\n",
        "    all_token_lists = []\n",
        "    ids = inputs[\"input_ids\"]  # shape [batch, seq_len]\n",
        "    for seq in ids:\n",
        "        seq_list = seq.tolist()\n",
        "        tokens = tokenizer.convert_ids_to_tokens(seq_list)\n",
        "        all_token_lists.append(tokens)\n",
        "    return all_token_lists\n",
        "\n",
        "# ---------- 2) heatmap for a single layer/head ----------\n",
        "def plot_attention_heatmap(attentions, inputs, tokenizer, layer=0, head=0, seq_index=0, figsize=(8,6), cmap='viridis'):\n",
        "    attn = attentions[layer][seq_index, head]   # shape [seq_len, seq_len]\n",
        "    attn_np = attn.detach().cpu().numpy()\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][seq_index].tolist())\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    sns.heatmap(attn_np, xticklabels=tokens, yticklabels=tokens, square=True, cbar=True, cmap=cmap)\n",
        "    plt.title(f\"Layer {layer} Head {head} (seq {seq_index})\")\n",
        "    plt.xlabel(\"Key tokens\")\n",
        "    plt.ylabel(\"Query tokens\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- 3) grid of head heatmaps for one layer ----------\n",
        "def plot_layer_heads(attentions, inputs, tokenizer, layer=0, seq_index=0, max_heads=12, figsize_per_plot=(3,3)):\n",
        "    heads = attentions[layer].size(1)\n",
        "    heads = min(heads, max_heads)\n",
        "    cols = min(6, heads)\n",
        "    rows = int(np.ceil(heads / cols))\n",
        "    fig_w = cols * figsize_per_plot[0]\n",
        "    fig_h = rows * figsize_per_plot[1]\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(fig_w, fig_h))\n",
        "    axes = axes.flatten()\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][seq_index].tolist())\n",
        "\n",
        "    for h in range(heads):\n",
        "        ax = axes[h]\n",
        "        attn_np = attentions[layer][seq_index, h].detach().cpu().numpy()\n",
        "        sns.heatmap(attn_np, ax=ax, cbar=False, xticklabels=tokens, yticklabels=tokens)\n",
        "        ax.set_title(f\"Layer:{layer} Head:{h}\")\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "    for i in range(heads, len(axes)):\n",
        "        fig.delaxes(axes[i])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- 4) histogram distributions per head ----------\n",
        "def plot_histograms(attentions, seq_index=0, bins=50, value_range=(0,0.3)):\n",
        "    num_layers = len(attentions)\n",
        "    num_heads = attentions[0].size(1)\n",
        "    fig, axes = plt.subplots(num_layers, num_heads, figsize=(num_heads*2, num_layers*1.8))\n",
        "    for l, layer_attn in enumerate(attentions):\n",
        "        attn = layer_attn[seq_index]  # [heads, seq_len, seq_len]\n",
        "        for h in range(num_heads):\n",
        "            ax = axes[l, h] if num_layers>1 else axes[h]\n",
        "            vals = attn[h].detach().cpu().numpy().flatten()\n",
        "            ax.hist(vals, bins=bins, range=value_range)\n",
        "            ax.set_title(f\"Layer:{l} Head:{h}\")\n",
        "            ax.set_xlim(value_range)\n",
        "            ax.set_ylim(0, None)\n",
        "            ax.set_xticks([value_range[0], value_range[1]])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- 5) attention rollout ----------\n",
        "def attention_rollout(attentions, discard_ratio=0.0):\n",
        "    avg_per_layer = [layer_attn.mean(1) for layer_attn in attentions]  # [batch, seq, seq]\n",
        "    batch = avg_per_layer[0].size(0)\n",
        "    seq_len = avg_per_layer[0].size(1)\n",
        "    device = avg_per_layer[0].device  # FIXED DEVICE\n",
        "    rollouts = []\n",
        "    for b in range(batch):\n",
        "        joint = torch.eye(seq_len, device=device)  # FIXED DEVICE\n",
        "        for L in avg_per_layer:\n",
        "            A = L[b]\n",
        "            if discard_ratio > 0:\n",
        "                flat = A.flatten()\n",
        "                thresh = torch.quantile(flat, discard_ratio)\n",
        "                A = torch.where(A < thresh, torch.zeros_like(A), A)\n",
        "            A = A + torch.eye(seq_len, device=A.device)  # FIXED DEVICE\n",
        "            A = A / A.sum(dim=-1, keepdim=True)\n",
        "            joint = A @ joint\n",
        "        rollouts.append(joint.detach().cpu().numpy())\n",
        "    return rollouts\n",
        "\n",
        "def plot_rollout(rollouts, inputs, tokenizer, seq_index=0):\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][seq_index].tolist())\n",
        "    mat = rollouts[seq_index]\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(mat, xticklabels=tokens, yticklabels=tokens, square=True, cbar=True)\n",
        "    plt.title(\"Attention rollout (token influence)\")\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- 6) head similarity matrix ----------\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "def head_similarity_matrix(attentions, layer, seq_index=0):\n",
        "    layer_attn = attentions[layer][seq_index]  # [heads, seq, seq]\n",
        "    H = layer_attn.size(0)\n",
        "    patterns = []\n",
        "    for h in range(H):\n",
        "        pat = layer_attn[h].detach().cpu().numpy().flatten()\n",
        "        patterns.append(pat)\n",
        "    sim = cosine_similarity(patterns)\n",
        "    return sim\n",
        "\n",
        "def plot_head_similarity(sim, layer):\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(sim, annot=True, fmt=\".2f\")\n",
        "    plt.title(f\"Head similarity (Layer {layer})\")\n",
        "    plt.xlabel(\"Head\")\n",
        "    plt.ylabel(\"Head\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ---------- 7) per-head CLS mass ----------\n",
        "def cls_mass_per_head(attentions, inputs, cls_index=0, seq_index=0):\n",
        "    masses = []\n",
        "    for l, layer_attn in enumerate(attentions):\n",
        "        a = layer_attn[seq_index]  # [heads, seq, seq]\n",
        "        mass_to_cls = a[:, :, cls_index].sum(axis=1).detach().cpu().numpy()\n",
        "        masses.append(mass_to_cls)\n",
        "    return np.stack(masses, axis=0)  # [layers, heads]\n",
        "\n",
        "def plot_cls_mass(mass_matrix):\n",
        "    layers, heads = mass_matrix.shape\n",
        "    plt.figure(figsize=(heads*0.5 + 3, layers*0.4 + 2))\n",
        "    sns.heatmap(mass_matrix, annot=False, cmap='magma')\n",
        "    plt.xlabel(\"Head\")\n",
        "    plt.ylabel(\"Layer\")\n",
        "    plt.title(\"Per-head mass attending TO CLS (rows=layers)\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.399325Z",
          "iopub.status.busy": "2025-10-07T22:07:55.399093Z",
          "iopub.status.idle": "2025-10-07T22:07:55.683475Z",
          "shell.execute_reply": "2025-10-07T22:07:55.682637Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.399308Z"
        },
        "id": "8xazzTYKxgAA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# assume tokenizer, model loaded; inputs tokenized; outputs computed\n",
        "attentions = output.attentions\n",
        "all_tokens = tokens_for_all(input, tokenizer)\n",
        "print(\"batch size:\", len(all_tokens))\n",
        "\n",
        "# Plot a single heatmap\n",
        "plot_attention_heatmap(attentions, input, tokenizer, layer=0, head=0, seq_index=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:55.684828Z",
          "iopub.status.busy": "2025-10-07T22:07:55.684453Z",
          "iopub.status.idle": "2025-10-07T22:07:58.037155Z",
          "shell.execute_reply": "2025-10-07T22:07:58.036224Z",
          "shell.execute_reply.started": "2025-10-07T22:07:55.684801Z"
        },
        "id": "XsPhdW51xgAB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Plot grid of heads for layer 0, example 0\n",
        "plot_layer_heads(attentions, input, tokenizer, layer=0, seq_index=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:58.038407Z",
          "iopub.status.busy": "2025-10-07T22:07:58.038044Z",
          "iopub.status.idle": "2025-10-07T22:07:58.364487Z",
          "shell.execute_reply": "2025-10-07T22:07:58.363662Z",
          "shell.execute_reply.started": "2025-10-07T22:07:58.038386Z"
        },
        "id": "Y7UVzAHoxgAC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Attention rollout and plot\n",
        "rollouts = attention_rollout(attentions, discard_ratio=0.0)\n",
        "plot_rollout(rollouts, input,tokenizer=tokenizer, seq_index=0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:58.365740Z",
          "iopub.status.busy": "2025-10-07T22:07:58.365379Z",
          "iopub.status.idle": "2025-10-07T22:07:58.871761Z",
          "shell.execute_reply": "2025-10-07T22:07:58.870900Z",
          "shell.execute_reply.started": "2025-10-07T22:07:58.365715Z"
        },
        "id": "H-u6Mm-BxgAC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Head similarity & visualization\n",
        "sim = head_similarity_matrix(attentions, layer=0, seq_index=0)\n",
        "plot_head_similarity(sim, layer=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:58.872976Z",
          "iopub.status.busy": "2025-10-07T22:07:58.872682Z",
          "iopub.status.idle": "2025-10-07T22:07:59.117485Z",
          "shell.execute_reply": "2025-10-07T22:07:59.116639Z",
          "shell.execute_reply.started": "2025-10-07T22:07:58.872952Z"
        },
        "id": "3SoekPVQxgAD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "# CLS mass across layers\n",
        "mass = cls_mass_per_head(attentions, input, cls_index=0, seq_index=0)\n",
        "plot_cls_mass(mass)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:07:59.118666Z",
          "iopub.status.busy": "2025-10-07T22:07:59.118391Z",
          "iopub.status.idle": "2025-10-07T22:08:02.501961Z",
          "shell.execute_reply": "2025-10-07T22:08:02.500954Z",
          "shell.execute_reply.started": "2025-10-07T22:07:59.118645Z"
        },
        "id": "JK0_y0ajxgAD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install captum --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:08:02.503662Z",
          "iopub.status.busy": "2025-10-07T22:08:02.503265Z",
          "iopub.status.idle": "2025-10-07T22:08:03.867172Z",
          "shell.execute_reply": "2025-10-07T22:08:03.866242Z",
          "shell.execute_reply.started": "2025-10-07T22:08:02.503638Z"
        },
        "id": "7_1YDaESxgAH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, layer_attention in enumerate(attentions):\n",
        "    # Get attention for the first (and only) item in the batch\n",
        "    # and average across all heads: shape becomes [seq_len, seq_len]\n",
        "    layer_attention_avg = layer_attention[0].mean(dim=0)\n",
        "\n",
        "    # Flatten the matrix to get a 1D array of weights\n",
        "    weights = layer_attention_avg.detach().cpu().numpy().flatten()\n",
        "\n",
        "    ax = axes[i]\n",
        "    ax.hist(weights, bins=50, color='skyblue', edgecolor='black')\n",
        "    ax.set_title(f'Layer {i}: Weight Distribution')\n",
        "    ax.set_xlabel('Attention Weight')\n",
        "    ax.set_ylabel('Frequency')\n",
        "\n",
        "plt.suptitle('Distribution of Attention Weights Across Layers (Averaged over Heads)', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:08:03.868409Z",
          "iopub.status.busy": "2025-10-07T22:08:03.868157Z",
          "iopub.status.idle": "2025-10-07T22:08:04.160675Z",
          "shell.execute_reply": "2025-10-07T22:08:04.159809Z",
          "shell.execute_reply.started": "2025-10-07T22:08:03.868388Z"
        },
        "id": "7OuD-lNjxgAI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --- You can change these values to explore different layers/heads ---\n",
        "LAYER_TO_VISUALIZE = 4\n",
        "HEAD_TO_VISUALIZE = 8\n",
        "# -------------------------------------------------------------------\n",
        "\n",
        "# Get attention weights for the specific layer and head\n",
        "attention_weights = attentions[LAYER_TO_VISUALIZE][0, HEAD_TO_VISUALIZE].detach().cpu().numpy()\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(attention_weights, xticklabels=tokens, yticklabels=tokens, cmap=\"viridis\")\n",
        "plt.title(f'Attention Heatmap for Layer {LAYER_TO_VISUALIZE}, Head {HEAD_TO_VISUALIZE}')\n",
        "plt.xlabel(\"Key Tokens (attended to)\")\n",
        "plt.ylabel(\"Query Tokens (attending from)\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:08:04.161987Z",
          "iopub.status.busy": "2025-10-07T22:08:04.161724Z",
          "iopub.status.idle": "2025-10-07T22:08:13.173192Z",
          "shell.execute_reply": "2025-10-07T22:08:13.172291Z",
          "shell.execute_reply.started": "2025-10-07T22:08:04.161959Z"
        },
        "id": "HDI0We6hxgAJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --- Plot 1 (Revised): Histogram for Each Head in Each Layer ---\n",
        "num_layers = len(attentions)\n",
        "num_heads = attentions[0].size(1) # Number of heads in the first layer\n",
        "\n",
        "fig, axes = plt.subplots(num_layers, num_heads, figsize=(20, 10))\n",
        "\n",
        "for layer_idx, layer_attention in enumerate(attentions):\n",
        "    # Get attention for the first (and only) item in the batch\n",
        "    attention_for_seq = layer_attention[0] # Shape: [num_heads, seq_len, seq_len]\n",
        "\n",
        "    for head_idx in range(num_heads):\n",
        "        # Get the specific head's attention matrix and flatten it\n",
        "        head_weights = attention_for_seq[head_idx].detach().cpu().numpy().flatten()\n",
        "\n",
        "        ax = axes[layer_idx, head_idx]\n",
        "        ax.hist(head_weights, bins=30, color='steelblue', edgecolor='black')\n",
        "        ax.set_title(f'L{layer_idx} H{head_idx}', fontsize=8)\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_xticklabels([])\n",
        "\n",
        "plt.suptitle('Distribution of Attention Weights for Each Head Across Layers', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:21:48.837003Z",
          "iopub.status.busy": "2025-10-07T22:21:48.836704Z",
          "iopub.status.idle": "2025-10-07T22:24:07.362098Z",
          "shell.execute_reply": "2025-10-07T22:24:07.361290Z",
          "shell.execute_reply.started": "2025-10-07T22:21:48.836983Z"
        },
        "id": "KRRpIO583u9L",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install shap lime spacy -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-10-07T22:28:18.053719Z",
          "iopub.status.busy": "2025-10-07T22:28:18.053324Z",
          "iopub.status.idle": "2025-10-07T22:28:48.613315Z",
          "shell.execute_reply": "2025-10-07T22:28:48.612393Z",
          "shell.execute_reply.started": "2025-10-07T22:28:18.053688Z"
        },
        "id": "7KaB2l3V3u9L",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from datasets import load_dataset\n",
        "import shap\n",
        "from lime import lime_text\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from collections import Counter\n",
        "\n",
        "# Your existing setup\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/distilbert-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/distilbert-NER\")\n",
        "ds = load_dataset(\"conll2003\",revision=\"convert/parquet\")  # Using the official conll2003 dataset\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "\n",
        "# Get label names from the model config\n",
        "label_names = model.config.id2label\n",
        "print(\"Label names:\", label_names)\n",
        "\n",
        "# Take one example from the validation set\n",
        "example_idx = 10  # Try a different index\n",
        "example = ds['validation'][example_idx]\n",
        "tokens = example['tokens']\n",
        "true_labels = example['ner_tags']\n",
        "\n",
        "print(\"Original example:\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"True labels: {[label_names[label] for label in true_labels]}\")\n",
        "\n",
        "# Prepare text for explanation\n",
        "text = \" \".join(tokens)\n",
        "print(f\"\\nText: {text}\")\n",
        "\n",
        "# 1. Run basic inference and display results\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"1. BASIC INFERENCE RESULTS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Tokenize the text\n",
        "inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, return_offsets_mapping=True)\n",
        "input_ids = inputs['input_ids'].to(device)\n",
        "attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "\n",
        "# Convert to human readable\n",
        "predicted_labels = predictions[0].cpu().numpy()\n",
        "tokenized_tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "\n",
        "print(\"Token-by-token analysis:\")\n",
        "for i, (token, pred_label) in enumerate(zip(tokenized_tokens, predicted_labels)):\n",
        "    if token not in ['[CLS]', '[SEP]', '[PAD]']:\n",
        "        print(f\"'{token}': Pred={label_names[pred_label]}\")\n",
        "\n",
        "# Align predictions with original tokens\n",
        "# This is tricky because of tokenization differences, so we'll use a simpler approach\n",
        "print(f\"\\nAligned predictions (first {len(tokens)} tokens):\")\n",
        "aligned_predictions = predicted_labels[1:len(tokens)+1]  # Skip CLS token\n",
        "for token, true_label, pred_label in zip(tokens, true_labels, aligned_predictions):\n",
        "    print(f\"'{token}': True={label_names[true_label]}, Pred={label_names[pred_label]}\")\n",
        "\n",
        "# 2. SHAP Explanation\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"2. SHAP EXPLANATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    # Simplified prediction function for SHAP\n",
        "    def predict_ner(texts):\n",
        "        model.eval()\n",
        "        batch_probs = []\n",
        "\n",
        "        for text in texts:\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
        "                             padding=True, max_length=128).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            # Remove batch dimension and take first few tokens to avoid memory issues\n",
        "            batch_probs.append(probs[0, 1:min(10, probs.shape[1]), :].cpu().numpy())\n",
        "\n",
        "        return np.concatenate(batch_probs, axis=0)\n",
        "\n",
        "    # Create SHAP explainer\n",
        "    explainer = shap.Explainer(predict_ner, tokenizer)\n",
        "\n",
        "    # Compute SHAP values for a shorter text to avoid memory issues\n",
        "    short_text = \" \".join(tokens[:8])  # Use first 8 tokens\n",
        "    shap_values = explainer([short_text])\n",
        "\n",
        "    # Visualize SHAP\n",
        "    print(f\"SHAP visualization for: {short_text}\")\n",
        "    shap.plots.text(shap_values[0], display=False)\n",
        "    plt.title(\"SHAP Explanation\")\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"SHAP failed: {e}\")\n",
        "    print(\"This is common due to memory constraints. Let's try a simpler approach...\")\n",
        "\n",
        "# 3. LIME Explanation\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"3. LIME EXPLANATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "try:\n",
        "    # Prediction function for LIME\n",
        "    def predict_proba(texts):\n",
        "        model.eval()\n",
        "        all_probs = []\n",
        "\n",
        "        for text in texts:\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True,\n",
        "                             padding=True, max_length=128).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(**inputs)\n",
        "                logits = outputs.logits\n",
        "\n",
        "            probs = torch.nn.functional.softmax(logits, dim=-1)\n",
        "            # Average probabilities across tokens (excluding special tokens)\n",
        "            token_probs = probs[0, 1:-1, :]  # Skip [CLS] and [SEP]\n",
        "            if token_probs.shape[0] > 0:\n",
        "                avg_probs = token_probs.mean(dim=0).cpu().numpy()\n",
        "            else:\n",
        "                avg_probs = np.zeros(probs.shape[-1])\n",
        "            all_probs.append(avg_probs)\n",
        "\n",
        "        return np.array(all_probs)\n",
        "\n",
        "    lime_explainer = LimeTextExplainer(class_names=list(label_names.values()))\n",
        "\n",
        "    # Explain a shorter text\n",
        "    short_text = \" \".join(tokens[:6])\n",
        "    exp = lime_explainer.explain_instance(\n",
        "        short_text,\n",
        "        predict_proba,\n",
        "        num_features=6,\n",
        "        top_labels=3\n",
        "    )\n",
        "\n",
        "    print(\"LIME Explanation:\")\n",
        "    print(f\"Top label: {list(label_names.values())[exp.top_labels[0]]}\")\n",
        "    for feature, weight in exp.as_list(label=exp.top_labels[0]):\n",
        "        print(f\"{feature}: {weight:.4f}\")\n",
        "\n",
        "    # Show LIME plot\n",
        "    exp.as_pyplot_figure(label=exp.top_labels[0])\n",
        "    plt.title(f\"LIME Explanation\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"LIME failed: {e}\")\n",
        "\n",
        "# 4. NER Visualization\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"4. NER VISUALIZATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Create a simple text-based visualization\n",
        "def visualize_ner_simple(tokens, labels, title=\"NER Results\"):\n",
        "    colors = {\n",
        "        'B-PER': '\\033[95m', 'I-PER': '\\033[95m',  # Magenta\n",
        "        'B-ORG': '\\033[94m', 'I-ORG': '\\033[94m',  # Blue\n",
        "        'B-LOC': '\\033[93m', 'I-LOC': '\\033[93m',  # Yellow\n",
        "        'B-MISC': '\\033[91m', 'I-MISC': '\\033[91m',  # Red\n",
        "        'O': '\\033[0m'  # Reset\n",
        "    }\n",
        "    reset_color = '\\033[0m'\n",
        "\n",
        "    print(f\"{title}:\")\n",
        "    result = []\n",
        "    for token, label_id in zip(tokens, labels):\n",
        "        label = label_names[label_id]\n",
        "        color = colors.get(label, '\\033[0m')\n",
        "        if label != 'O':\n",
        "            result.append(f\"{color}{token}({label}){reset_color}\")\n",
        "        else:\n",
        "            result.append(token)\n",
        "    print(\" \".join(result))\n",
        "    print()\n",
        "\n",
        "# Visualize true and predicted labels\n",
        "visualize_ner_simple(tokens, true_labels, \"TRUE LABELS\")\n",
        "visualize_ner_simple(tokens, aligned_predictions, \"PREDICTED LABELS\")\n",
        "\n",
        "# Alternative: Create a color-coded display using matplotlib\n",
        "def plot_ner_comparison(tokens, true_labels, pred_labels):\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 6))\n",
        "\n",
        "    # Color mapping\n",
        "    color_map = {\n",
        "        'B-PER': 'pink', 'I-PER': 'lightpink',\n",
        "        'B-ORG': 'lightblue', 'I-ORG': 'lightcyan',\n",
        "        'B-LOC': 'lightyellow', 'I-LOC': 'lemonchiffon',\n",
        "        'B-MISC': 'lightcoral', 'I-MISC': 'mistyrose',\n",
        "        'O': 'white'\n",
        "    }\n",
        "\n",
        "    # Plot true labels\n",
        "    y_pos = 0\n",
        "    for i, (token, label_id) in enumerate(zip(tokens, true_labels)):\n",
        "        label = label_names[label_id]\n",
        "        color = color_map.get(label, 'white')\n",
        "        ax1.add_patch(plt.Rectangle((i, 0), 1, 1, color=color))\n",
        "        ax1.text(i + 0.5, 0.5, f\"{token}\\n({label})\",\n",
        "                ha='center', va='center', fontsize=8)\n",
        "        ax1.set_xlim(0, len(tokens))\n",
        "        ax1.set_ylim(0, 1)\n",
        "        ax1.set_title('True Labels')\n",
        "        ax1.set_xticks([])\n",
        "        ax1.set_yticks([])\n",
        "\n",
        "    # Plot predicted labels\n",
        "    for i, (token, label_id) in enumerate(zip(tokens, pred_labels)):\n",
        "        label = label_names[label_id]\n",
        "        color = color_map.get(label, 'white')\n",
        "        ax2.add_patch(plt.Rectangle((i, 0), 1, 1, color=color))\n",
        "        ax2.text(i + 0.5, 0.5, f\"{token}\\n({label})\",\n",
        "                ha='center', va='center', fontsize=8)\n",
        "        ax2.set_xlim(0, len(tokens))\n",
        "        ax2.set_ylim(0, 1)\n",
        "        ax2.set_title('Predicted Labels')\n",
        "        ax2.set_xticks([])\n",
        "        ax2.set_yticks([])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create the comparison plot\n",
        "plot_ner_comparison(tokens[:10], true_labels[:10], aligned_predictions[:10])\n",
        "\n",
        "# 5. Summary Statistics\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"5. SUMMARY STATISTICS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Calculate accuracy\n",
        "correct = sum(1 for t, p in zip(true_labels, aligned_predictions) if t == p)\n",
        "accuracy = correct / len(true_labels)\n",
        "\n",
        "print(f\"Token-level Accuracy: {accuracy:.2%}\")\n",
        "print(f\"Correct: {correct}/{len(true_labels)}\")\n",
        "\n",
        "# Label distribution\n",
        "true_counter = Counter([label_names[l] for l in true_labels])\n",
        "pred_counter = Counter([label_names[l] for l in aligned_predictions])\n",
        "\n",
        "print(\"\\nTrue label distribution:\")\n",
        "for label, count in true_counter.most_common():\n",
        "    print(f\"  {label}: {count}\")\n",
        "\n",
        "print(\"\\nPredicted label distribution:\")\n",
        "for label, count in pred_counter.most_common():\n",
        "    print(f\"  {label}: {count}\")\n",
        "\n",
        "# Confusion matrix for major entity types\n",
        "print(\"\\nEntity-level analysis:\")\n",
        "entity_types = ['PER', 'ORG', 'LOC', 'MISC']\n",
        "\n",
        "for entity_type in entity_types:\n",
        "    true_entities = sum(1 for label in true_labels if label_names[label].endswith(entity_type))\n",
        "    pred_entities = sum(1 for label in aligned_predictions if label_names[label].endswith(entity_type))\n",
        "    print(f\"{entity_type}: True={true_entities}, Pred={pred_entities}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31154,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
